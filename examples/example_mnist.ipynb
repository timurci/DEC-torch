{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35468625-780e-4a48-9bf3-92f915cd1f7b",
   "metadata": {},
   "source": [
    "# DEC Training on Torchvision MNIST Dataset\n",
    "This notebook provides an example workflow on training and I/O operations of DEC models, and shows how to compute clustering performance metrics and visualize embedding clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950983f-941d-4053-8845-42ae99eafff1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Setup\n",
    "\n",
    "Package requirements:\n",
    "- dec_torch\n",
    "- torchvision\n",
    "\n",
    "1. Specify global torch computation device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f06a73-b7f5-4e7d-b21b-9e698187bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "# Computation device\n",
    "device = \"cuda\"\n",
    "\n",
    "# Dataset source and image properties\n",
    "torchvision_dataset = torchvision.datasets.MNIST\n",
    "dataset_root = \"dataset\"  # Path to download the dataset\n",
    "height, width, channels = 28, 28, 1\n",
    "input_dim = height * width * channels\n",
    "\n",
    "# Training epochs and stopping criteria\n",
    "autoencoder_pretraining_epoch = 10000\n",
    "autoencoder_finetuning_epoch = 10000\n",
    "dec_reassignment_tolerance = 0.001\n",
    "\n",
    "# Output paths\n",
    "output_dir = \"output\"\n",
    "j = lambda x : os.path.join(output_dir, x)\n",
    "autoencoder_pretrained_output = j(\"pretrained.stacked.autoencoder.pth\")\n",
    "autoencoder_finetuned_output = j(\"finetuned.stacked.autoencoder.pth\")\n",
    "dec_encoder_output = j(\"dec.encoder.pth\")\n",
    "dec_centroids_output = j(\"dec.centroids.pth\")\n",
    "\n",
    "# DEC K-means initialization\n",
    "kmeans_trials = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004b868-81c5-4b2e-9a33-be6fb721ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir, exist_ok=True)\n",
    "\n",
    "import warnings\n",
    "from tqdm import TqdmWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=TqdmWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391f27f-a41d-43b0-a8b0-f2408adc8d2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941aeee4-6e22-4f6d-b6d5-0fcaee748377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Lambda(torch.flatten)\n",
    "])\n",
    "\n",
    "training_set = torchvision_dataset(dataset_root, train=True, transform=transform, download=True)\n",
    "validation_set = torchvision_dataset(dataset_root, train=False, transform=transform, download=True)\n",
    "\n",
    "print(\"Training   set size:\", len(training_set))\n",
    "print(\"Validation set size:\", len(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2dd963-6a5b-48e3-af78-fa230da225d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option - Dataset without label (used while training the models)\n",
    "class UnlabeledDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset: torch.utils.data.Dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, _ = self.dataset[idx]\n",
    "        return image\n",
    "\n",
    "training_set_unlabeled = UnlabeledDataset(training_set)\n",
    "validation_set_unlabeled = UnlabeledDataset(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bae518-8bd0-41ce-9f63-5ebeade3bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option - Extract all unlabeled data to memory (faster alternative)\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from dec_torch.utils.data import extract_all_data\n",
    "\n",
    "training_input_cpu, training_labels = extract_all_data(DataLoader(training_set))\n",
    "validation_input_cpu, validation_labels = extract_all_data(DataLoader(validation_set))\n",
    "\n",
    "# This can be skipped if you want to use swap memory or all GPU memory.\n",
    "# If you skip pinning the whole tensor, then consider setting `pin_memory=True` in DataLoader instead.\n",
    "# training_input = training_input.pin_memory()\n",
    "# validation_input = validation_input.pin_memory()\n",
    "\n",
    "# Load all data to cuda device if you can afford it.\n",
    "training_input = training_input_cpu.to(device)\n",
    "validation_input = validation_input_cpu.to(device)\n",
    "\n",
    "training_set_unlabeled = TensorDataset(training_input)\n",
    "validation_set_unlabeled = TensorDataset(validation_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f094d8c-9725-4936-8777-7c90c214da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preview_images(dataset, indices: list[int], channels, height, width, cmap=\"grey\"):\n",
    "    images = [dataset[idx] for idx in indices]\n",
    "    images = [img[0] if isinstance(img, (tuple, list)) else img for img in images]\n",
    "    images = [img.cpu() for img in images]\n",
    "    images = [img.view(channels, height, width) for img in images]\n",
    "    images = [img.permute(1, 2, 0) for img in images]\n",
    "\n",
    "    plt.figure(figsize=(2 * len(indices), 2))\n",
    "    for i, img in enumerate(images, start=1):\n",
    "        plt.subplot(1, len(indices), i)\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "preview_images(\n",
    "    dataset=training_set_unlabeled,\n",
    "    indices=list(torch.randint(0, 5000, (10,))),\n",
    "    channels=channels,\n",
    "    height=height,\n",
    "    width=width\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5319e12-b040-43b8-97b7-c57c96cf9c31",
   "metadata": {},
   "source": [
    "## 3. Stacked Autoencoder Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122121c6-bad2-4d51-9ede-8b6842580ffc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.1 Greedy Layer-wise Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a9d32-3a42-45b1-ba15-cd236250c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run after \"2. Data Loading\"\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set num_workers if data is not already loaded on GPU\n",
    "training_loader = DataLoader(training_set_unlabeled, batch_size=256)\n",
    "validation_loader = DataLoader(validation_set_unlabeled, batch_size=256)\n",
    "\n",
    "\n",
    "from dec_torch.autoencoder import StackedAutoEncoder, CoderConfig, StackedAutoEncoderConfig\n",
    "\n",
    "latent_dims = [500, 500, 2000, 10]\n",
    "sae_config = StackedAutoEncoderConfig.build(\n",
    "    input_dim=input_dim,\n",
    "    latent_dims=latent_dims,\n",
    "    input_dropout=.2,\n",
    ")\n",
    "\n",
    "model = StackedAutoEncoder(sae_config).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b44fd-78e4-4f0b-b794-d020ba428264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train stacked autoencoder\n",
    "from torch import nn\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "history = model.greedy_fit(\n",
    "    training_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    val_loader=validation_loader,\n",
    "    n_epoch=autoencoder_pretraining_epoch,\n",
    "    max_verbose=10\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"Elapsed time\", end_time - start_time)\n",
    "\n",
    "model.save(autoencoder_pretrained_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaecb12-bc5f-441b-a6d9-b60df510de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training-Validation loss history\n",
    "from dec_torch.utils.visualization import loss_plot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(len(history), 1, figsize=(8, 10), sharex=True)\n",
    "for i, (ax, h) in enumerate(zip(axes, history)):\n",
    "    loss_plot(h[h[\"epoch\"] > 10], ax=ax).set_title(\"Autoencoder \" + str(i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89430909-e862-4d5b-81e2-0904695e569c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.2 Fine-tuning Stacked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407b158-77b7-46c0-a44a-2099819b00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model, output path, dataloader\n",
    "# Run after \"2. Data Loading\"\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set num_workers if data is not already loaded on GPU\n",
    "training_loader = DataLoader(training_set_unlabeled, batch_size=256)\n",
    "validation_loader = DataLoader(validation_set_unlabeled, batch_size=256)\n",
    "\n",
    "\n",
    "from dec_torch.autoencoder import StackedAutoEncoder, CoderConfig, StackedAutoEncoderConfig\n",
    "\n",
    "pretrained_sae = StackedAutoEncoder.load(autoencoder_pretraining_output, map_location=\"cpu\")\n",
    "\n",
    "finetune_config = pretrained_sae.config.replace_input_dropout(None)\n",
    "model = StackedAutoEncoder(finetune_config)\n",
    "\n",
    "model.load_state_dict(pretrained_sae.state_dict())\n",
    "model = model.to(device)\n",
    "\n",
    "del pretrained_sae\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca892e-7163-4646-8168-1d46d2b240f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train stacked autoencoder\n",
    "from torch import nn\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "history = model.fit(\n",
    "    training_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    val_loader=validation_loader,\n",
    "    n_epoch=autoencoder_finetuning_epoch,\n",
    "    max_verbose=10\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"Elapsed time\", end_time - start_time)\n",
    "\n",
    "model.save(autoencoder_finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f35943e-6adf-45ea-9a3d-c4bb7bab2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training-Validation loss history\n",
    "from dec_torch.utils.visualization import loss_plot\n",
    "\n",
    "loss_plot(history[history[\"epoch\"] > 10]).set_title(\"SAE Fine-tuning Loss Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9677410-bbf3-420e-8d76-ccc7c1e80010",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. DEC Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98f51a-c5d2-4a9e-832a-b40569009a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run after \"2. Data Loading\"\n",
    "# Extract embeddings and true labels\n",
    "from dec_torch.autoencoder import StackedAutoEncoder\n",
    "from dec_torch.utils.data import extract_all_data\n",
    "\n",
    "# Ensure autoencoder is loaded to \"cpu\" for k-means initialization.\n",
    "autoencoder = StackedAutoEncoder.load(autoencoder_finetuned_output, map_location=\"cpu\")\n",
    "\n",
    "# Use torch.utils.data.Subset if the amount of training samples is too much.\n",
    "# embeddings, labels_true = extract_all_data(TensorDataset(training_input), transform=autoencoder.encoder)\n",
    "embeddings = None\n",
    "with torch.no_grad():\n",
    "    embeddings = autoencoder.encoder(training_input_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ebd2e9-5788-42cc-a231-93dd6a587076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means centroid initialization\n",
    "from dec_torch import dec\n",
    "\n",
    "clusters_list, clusters_scores = dec.init_clusters_trials(embeddings, n_clusters=10, n_trials=kmeans_trials)\n",
    "\n",
    "selected_index = clusters_scores.iloc[0].name\n",
    "centroids = clusters_list[selected_index]\n",
    "\n",
    "print(f\"Selected clusters #{selected_index}\")\n",
    "clusters_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe5779-9893-40e2-8e56-ab8832606561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictied labels\n",
    "labels_pred = None\n",
    "with torch.no_grad():\n",
    "    labels_pred = torch.argmax(dec.DEC.soft_assignment(embeddings, centroids, alpha=1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35abcefd-ea64-44c4-b563-9d3e241fa9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score\n",
    ")\n",
    "\n",
    "ari = adjusted_rand_score(training_labels, labels_pred)\n",
    "print(\"ARI\", ari)\n",
    "\n",
    "nmi = normalized_mutual_info_score(training_labels, labels_pred)\n",
    "print(\"NMI\", nmi)\n",
    "\n",
    "if not len(labels_pred.unique()) == 1:\n",
    "    sil = silhouette_score(embeddings, labels_pred)\n",
    "    print(\"SIL\", sil)\n",
    "    ch = calinski_harabasz_score(embeddings, labels_pred)\n",
    "    print(\"CH \", ch)\n",
    "else:\n",
    "    print(\"Cannot compute silhouette (SIL) and calinski-harabasz (CH) scores.\")\n",
    "    print(\"There is only one cluster in the labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6240855-1035-4ef0-972b-4406f9b20152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from dec_torch.utils.visualization import cluster_plot\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for ax, (label_type, labels) in zip(axes, [(\"true label\", training_labels), (\"pred. label\", labels_pred)]):\n",
    "    cluster_plot(\n",
    "        embeddings,\n",
    "        labels,\n",
    "        reduction=\"umap\",\n",
    "        centroids=centroids,\n",
    "        centroids_options = {\"marker\": \"s\", \"color\": \"blue\", \"s\": 50},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(label_type)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a33115-d84a-48f4-8b21-95279d496a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_loader = DataLoader(training_set_unlabeled, batch_size=256)\n",
    "validation_loader = DataLoader(validation_set_unlabeled, batch_size=256)\n",
    "\n",
    "model = dec.DEC(autoencoder.encoder, centroids).to(device)\n",
    "\n",
    "del clusters_list, clusters_scores, embeddings, labels_pred, centroids\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274757e3-147e-43ac-a2fd-a8b015c7e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DEC\n",
    "from torch import nn\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from dec_torch import dec\n",
    "criterion = dec.dec.KLDivLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "history = model.fit(\n",
    "    training_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    val_loader=validation_loader,\n",
    "    tolerance=dec_reassignment_tolerance,\n",
    "    max_verbose=1000,\n",
    "    max_epoch=10000\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"Elapsed time\", end_time - start_time)\n",
    "\n",
    "dec.io.save(model, dec_encoder_output, dec_centroids_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f10052-ce62-4130-84fe-2e8feb1cd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training-Validation loss history\n",
    "from dec_torch.utils.visualization import loss_plot\n",
    "\n",
    "loss_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888abd52-c8f2-4747-9109-8c152e824275",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Cluster Visualization \\& Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b614ea-bd4c-4d01-b389-22e13c4dec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DEC model\n",
    "# Run after \"2. Data Loading\"\n",
    "from dec_torch import dec\n",
    "\n",
    "dec_model = dec.io.load(dec_encoder_output, dec_centroids_output, sequential_encoder=True, map_location=\"cpu\")\n",
    "dec_model.eval()\n",
    "\n",
    "print(\"DEC centroids shape:\", dec_model.centroids.shape)\n",
    "dec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd41ac6-6ca9-4311-b631-0a42683c05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training inputs, embeddings, true and predicted labels\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from dec_torch.utils.data import extract_all_data\n",
    "# inputs, labels_true = extract_all_data(DataLoader(training_set))\n",
    "\n",
    "embeddings = None\n",
    "labels_pred = None\n",
    "with torch.no_grad():\n",
    "    embeddings = dec_model.encoder(training_input_cpu)  # TODO: Consider using hook instead of calling the model twice\n",
    "    labels_pred = torch.argmax(dec_model(training_input_cpu), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2486cef-b606-468d-9c7a-186922234838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score\n",
    ")\n",
    "\n",
    "ari = adjusted_rand_score(training_labels, labels_pred)\n",
    "print(\"ARI\", ari)\n",
    "\n",
    "nmi = normalized_mutual_info_score(training_labels, labels_pred)\n",
    "print(\"NMI\", nmi)\n",
    "\n",
    "if not len(labels_pred.unique()) == 1:\n",
    "    sil = silhouette_score(embeddings, labels_pred)\n",
    "    print(\"SIL\", sil)\n",
    "    ch = calinski_harabasz_score(embeddings, labels_pred)\n",
    "    print(\"CH \", ch)\n",
    "else:\n",
    "    print(\"Cannot compute silhouette (SIL) and calinski-harabasz (CH) scores.\")\n",
    "    print(\"There is only one cluster in the labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3be1c2-d574-487d-bf90-26f3bc80fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dec_torch.utils.visualization import cluster_plot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for ax, (label_type, labels) in zip(axes, [(\"true label\", training_labels), (\"pred. label\", labels_pred)]):\n",
    "    cluster_plot(\n",
    "        embeddings,\n",
    "        labels,\n",
    "        reduction=\"umap\",\n",
    "        centroids=dec_model.centroids.detach().cpu(),\n",
    "        centroids_options = {\"marker\": \"s\", \"color\": \"blue\", \"s\": 50},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(label_type)\n",
    "\n",
    "del embeddings, labels_pred\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7993d90-527b-4ae2-9f37-8fd4c010e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Validation Data\n",
    "\n",
    "#from dec_torch.utils.data import extract_all_data\n",
    "# inputs, labels_true = extract_all_data(DataLoader(validation_set))\n",
    "\n",
    "embeddings = None\n",
    "labels_pred = None\n",
    "with torch.no_grad():\n",
    "    embeddings = dec_model.encoder(validation_input_cpu)\n",
    "    labels_pred = torch.argmax(dec_model(validation_input_cpu), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c02a90-094a-4f0c-8362-cfc101002e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score\n",
    ")\n",
    "\n",
    "ari = adjusted_rand_score(labels_true, labels_pred)\n",
    "print(\"ARI\", ari)\n",
    "\n",
    "nmi = normalized_mutual_info_score(labels_true, labels_pred)\n",
    "print(\"NMI\", nmi)\n",
    "\n",
    "if not len(labels_pred.unique()) == 1:\n",
    "    sil = silhouette_score(embeddings, labels_pred)\n",
    "    print(\"SIL\", sil)\n",
    "    ch = calinski_harabasz_score(embeddings, labels_pred)\n",
    "    print(\"CH \", ch)\n",
    "else:\n",
    "    print(\"Cannot compute silhouette (SIL) and calinski-harabasz (CH) scores.\")\n",
    "    print(\"There is only one cluster in the labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b84430-f0c3-45e9-9529-f798632b3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dec_torch.utils.visualization import cluster_plot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "for ax, (label_type, labels) in zip(axes, [(\"true label\", training_labels), (\"pred. label\", labels_pred)]):\n",
    "    cluster_plot(\n",
    "        embeddings,\n",
    "        labels,\n",
    "        reduction=\"umap\",\n",
    "        centroids=dec_model.centroids.detach().cpu(),\n",
    "        centroids_options = {\"marker\": \"s\", \"color\": \"blue\", \"s\": 50},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(label_type)\n",
    "\n",
    "del embeddings, labels_pred\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEC Kernel - Python 3.10",
   "language": "python",
   "name": "dec-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
